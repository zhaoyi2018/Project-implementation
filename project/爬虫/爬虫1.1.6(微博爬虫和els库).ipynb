{"cells":[{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"e8129e97","execution_millis":2627,"cell_id":"00000-1a0d5770-c968-4ccc-9210-95b5e2975b5a","is_code_hidden":false,"execution_start":1606702574012},"source":"#!/usr/bin/python \n# -*- coding: utf-8 -*-\n!pip install bs4==0.0.1\n!pip install elasticsearch==7.10.0","execution_count":31,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bs4==0.0.1 in /opt/venv/lib/python3.7/site-packages (0.0.1)\nRequirement already satisfied: beautifulsoup4 in /opt/venv/lib/python3.7/site-packages (from bs4==0.0.1) (4.9.3)\nRequirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /opt/venv/lib/python3.7/site-packages (from beautifulsoup4->bs4==0.0.1) (2.0.1)\nRequirement already satisfied: elasticsearch==7.10.0 in /opt/venv/lib/python3.7/site-packages (7.10.0)\nRequirement already satisfied: urllib3<2,>=1.21.1 in /opt/venv/lib/python3.7/site-packages (from elasticsearch==7.10.0) (1.26.2)\nRequirement already satisfied: certifi in /opt/venv/lib/python3.7/site-packages (from elasticsearch==7.10.0) (2020.11.8)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**随机睡眠**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00001-769ecb41-5356-4f09-8bf2-2f0d4c9a09da","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"57060f22","execution_millis":4,"cell_id":"00001-1f17f328-5f32-4671-95c3-3d8cf60be54a","is_code_hidden":false,"execution_start":1606702576645},"source":"def random_sleep():\n    from random import randint\n    from time import sleep\n    sleep_time = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0]\n    index = randint(0, len(sleep_time)-1)\n    sleep(sleep_time[index])","execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"**随机表头**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00003-e4178fc6-3961-45b3-8eb2-b67ae9d448d6","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"35ece208","execution_millis":1,"cell_id":"00002-b124d13f-1107-436b-ba84-910690ce3f38","is_code_hidden":false,"execution_start":1606702576654},"source":"def random_header():\n    from random import randint\n    header_list = [\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1\",\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0) Gecko/20100101 Firefox/6.0\",\n    \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50\",\n    \"Opera/9.80 (Windows NT 6.1; U; zh-cn) Presto/2.9.168 Version/11.50\",\n    \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 2.0.50727; SLCC2; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.3; .NET4.0C; Tablet PC 2.0; .NET4.0E)\",\n    \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; .NET4.0C; InfoPath.3)\",\n    \"Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; GTB7.0)\",\n    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)\",\n    \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1)\",\n    \"Mozilla/5.0 (Windows; U; Windows NT 6.1; ) AppleWebKit/534.12 (KHTML, like Gecko) Maxthon/3.0 Safari/534.12\",\n    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.3; .NET4.0C; .NET4.0E)\",\n    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.3; .NET4.0C; .NET4.0E; SE 2.X MetaSr 1.0)\",\n    \"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.3 (KHTML, like Gecko) Chrome/6.0.472.33 Safari/534.3 SE 2.X MetaSr 1.0\",\n    \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.3; .NET4.0C; .NET4.0E)\",\n    \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.41 Safari/535.1 QQBrowser/6.9.11079.201\",\n    \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.1; WOW64; Trident/5.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; Media Center PC 6.0; InfoPath.3; .NET4.0C; .NET4.0E) QQBrowser/6.9.11079.201\",\n    \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)\"]\n    index = randint(0, len(header_list)-1)\n    return {\"user-agent\":header_list[index]}","execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**评论内容预处理**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00005-042a80aa-af43-40be-a595-c24ae14ecf5f","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"a24e2ee4","execution_millis":0,"cell_id":"00003-8e6866fb-fd32-42e5-b016-4cecb0d9cdae","is_code_hidden":true,"execution_start":1606702576664},"source":"def re_filter(content):\n    '''\n    使用re工具, 处理冗余信息\n    '''\n    import re\n\n    pattern1 = re.compile(r'#[^#]+#')\n    pattern2 = re.compile(r\"[a-zA-Z]\")\n    return re.sub(pattern2, \"\", re.sub(pattern1, \"\", content))","execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"**评论内容预处理**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00007-0d14471d-46de-4bd0-95c1-93ff559d87cc","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"39c3e294","execution_millis":2,"cell_id":"00004-cdec0e2b-ac52-4a46-9d78-dd563e219870","is_code_hidden":false,"execution_start":1606702576672},"source":"def get_info(res, title_name=\"\", get_content=True):\n    '''\n    处理json数据, 获取指定的内容(题目和评论)或其他内容\n    \n    Parameters:\n        res - request请求后, 返回的response\n        title_name - 该评论评价的, 是什么热点题目\n        get_content - 判断res请求的网站类型\n\n    Returns:\n        content - 依据情况, 返回指定内容\n    '''\n    from bs4 import BeautifulSoup\n    from time import sleep\n\n    if res.status_code != 200 or res.json()[\"ok\"] != 1:\n        print(\"ip被封!, 等候3s\")\n        sleep(3)\n        if get_content:\n            return -1, 0\n        else:\n            return []\n    \n    contents_dict = res.json()[\"data\"]\n    if get_content:\n        # 判断是否为浏览页\n        ## 如果是\n        if \"max_id\" not in contents_dict:\n            mid_list = []\n            for item in contents_dict[\"cards\"]:\n                # 如果mid_list大于3, 就跳出\n                if len(mid_list)>=3:\n                    break\n                # 判断评论类型\n                if item[\"card_type\"] != 9:\n                    continue\n                # 获取mid\n                mid_list.append(item[\"mblog\"][\"id\"])\n            return 1, mid_list\n        else:  \n        # 如果不是\n            contents_list = []\n            # 获取下一页\n            max_id = contents_dict[\"max_id\"]\n\n            month_dict = {\"Jan\":\"01\", \"Feb\":\"02\", \"Mar\":\"03\", \"Apr\":\"04\", \"May\":\"05\", \"Jun\":\"06\", \"Jul\":\"07\",\"Aug\":\"08\", \"Sep\":\"09\", \"Oct\":\"10\",\"Nov\":\"11\",\"Dec\":\"12\"}\n            for item in contents_dict[\"data\"]:\n\n                # 获取评论内容和时间\n                content = item[\"text\"]\n                time_list = item[\"created_at\"].split(\" \")\n                created_time = \"{}-{}-{}\".format(time_list[-1], month_dict[time_list[1]], time_list[2])\n\n                # 使用beautifulSoup\n                bf = BeautifulSoup(content)\n                content = \"\"\n                for p in bf.stripped_strings:\n                    content += p\n                \n                # 使用re工具, 将##内容全部清除\n                content = re_filter(content)\n                if content==\"\" or \"转发\" in content:\n                    continue\n                contents_list.append((title_name, content, created_time))\n            return max_id, contents_list\n    else:\n        ## 获取es库已存在title\n        old_title = all_es_search(key=\"title\")\n\n        keyword_list = []\n        for item in contents_dict[\"cards\"][0][\"card_group\"]:\n            keyword = str(item[\"desc\"])\n            if keyword not in old_title:\n                keyword_list.append(keyword)\n        return keyword_list","execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"**评论数据推入ES库**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00008-6076f2b0-76c8-44be-aad8-8c80483ca0bf","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"aa3149b6","execution_millis":3,"cell_id":"00005-b8824642-2183-45ef-ae1c-47a41a9b55b0","is_code_hidden":false,"execution_start":1606702576678},"source":"def push_es(content_list):\n    '''\n    将数据推入云es库中\n    '''\n    # 考虑列表为空时, 直接跳出\n    if len(content_list)==0:\n        return\n    \n    # 列表非空时, 开始推入\n    from elasticsearch import Elasticsearch\n    from elasticsearch import helpers\n    # 开始连接es库(感觉这里可以优化)\n    es = Elasticsearch(\n        ['es-cn-09k1xdlqf000a7yyn.public.elasticsearch.aliyuncs.com'],\n        http_auth=('elastic', 'Zy13720028637'),\n        port=9200,\n        use_ssl=False\n    )\n    # 判断数据是否为字典类型\n    if type(content_list[0]) != dict:\n        names = [\"title\", \"describe\", \"createData\"]\n        for i, data in enumerate(content_list):\n            temp_dict = {}\n            for index, content in enumerate(data):\n                temp_dict[names[index]] = content\n            content_list[i] = temp_dict\n    # 将数据修饰一下\n    action = ({\n        \"_index\":\"hot_news\",\n        \"_type\":\"comment\",\n        \"_source\":data\n    } for data in content_list)\n    # 导入数据\n    helpers.bulk(es, action, request_timeout=30)","execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"**评论网页内容的抓取**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00010-2095784d-5f2d-4ff0-92d5-ccb4f9260256","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"811e8f8d","execution_millis":2,"cell_id":"00006-c186531c-c557-4c88-b730-e2cd3dcb8d4d","is_code_hidden":false,"execution_start":1606702576687},"source":"def web_grap(keyword):\n    '''\n    网页抓取\n\n    Parameters:\n        keyword - 热点新闻\n\n    Returns:\n        无\n    '''\n    import requests\n    import pandas as pd\n    \n    base_url = \"https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D1%26q%3D%23{}%23&page_type=searchall&page={}\"\n    # headers = {\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36 Edg/86.0.622.63\"}\n    print(\"\\n抓取热度:{}\".format(keyword))\n\n    # 第一步抓取热点号\n    while True:\n        url = base_url.format(keyword, 0)\n        random_sleep()\n        res = requests.get(url.format(keyword, 1), headers=random_header())\n        status, mid_list = get_info(res)\n        # 判断ip是否被封\n        if status==-1:\n            print(\"再次申请...\")\n            continue\n        else:\n            break\n    \n    base_url = \"https://m.weibo.cn/comments/hotflow?id={}&mid={}&max_id={}\"\n    num = 0\n    cookie = {\"Cookie\":\"_T_WM=31420914776;M_WEIBOCN_PARAMS=luicode%3D20000174 ;WEIBOCN_FROM=1110006030; XSRF-TOKEN=6456fc; MLOGIN=1 ;SUB=_2A25yuiimDeRhGeRO61IS9yvLyT-IHXVuRUjurDV6PUJbkdANLWrjkW1NUIeUSgyof564-cNUpoux4c760jBpCOPX\"}\n    for i in range(len(mid_list)):\n        flag = 0\n        max_id = 0\n        while True:\n            # 正常抓取\n            url = base_url.format(mid_list[i], mid_list[i], max_id)\n            # print(url)\n            random_sleep()\n            res = requests.get(url, cookies=cookie, headers=random_header())\n            temp, contents_list = get_info(res, keyword)\n\n            # 判断ip是否被封\n            if temp ==-1:\n                flag += 1\n                if flag == 1:\n                    print(\"  跳出此次申请...\")\n                    break\n                print(\"  再次申请...\")\n                continue\n            flag = 0\n            num += len(contents_list)\n            max_id = temp\n\n            ## 存储数据到es中\n            push_es(contents_list)\n            print(\" 已抓取{}条评论!!\".format(num))\n\n            # 判断是否满足跳出条件\n            if max_id == 0:\n                break\n    print(\"{}抓取结束!\".format(keyword))\n","execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"**用于抓取微博热点标题**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00012-33d0577d-f282-4a46-a0af-02c9992f4e08","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"f2f1af02","execution_millis":0,"cell_id":"00007-af5365f0-32dd-47ac-9242-74ffb4c4f084","is_code_hidden":false,"execution_start":1606702576693},"source":"def to_more_grap():\n    '''\n    用于获取相关热度的关键词\n\n    Parameters:\n        无\n    \n    Returns:\n        content_list - 热点新闻列表\n    '''\n    import requests\n    \n    # 准备网站\n    # base_url = \"https://m.weibo.cn/api/container/getIndex?containerid=231583&page_type=searchall\"\n    base_url = \"https://m.weibo.cn/api/container/getIndex?containerid=106003type%3D25%26t%3D3%26disable_hot%3D1%26filter_type%3Drealtimehot&title=%E5%BE%AE%E5%8D%9A%E7%83%AD%E6%90%9C&extparam=seat%3D1%26pos%3D0_0%26mi_cid%3D100103%26cate%3D10103%26filter_type%3Drealtimehot%26c_type%3D30%26display_time%3D1606374389&luicode=10000011&lfid=231583\"\n    cookie = {\"Cookie\":\"_T_WM=31420914776;M_WEIBOCN_PARAMS=luicode%3D20000174 ;WEIBOCN_FROM=1110006030; XSRF-TOKEN=6456fc; MLOGIN=1 ;SUB=_2A25yuiimDeRhGeRO61IS9yvLyT-IHXVuRUjurDV6PUJbkdANLWrjkW1NUIeUSgyof564-cNUpoux4c760jBpCOPX\"}\n    \n    ## 准备https头部\n    # headers = {\"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36 Edg/86.0.622.63\"}\n    # ## 睡眠\n    random_sleep()\n    ## 开始访问\n    res = requests.get(base_url, headers=random_header(), cookies=cookie)\n    ## 处理json数据, 获取更多问题号\n    contents_list = get_info(res, get_content=False)\n    return contents_list","execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# **整合爬虫相关代码, 实现爬取流程**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00014-655e710f-4a8f-41d1-8987-b4d19ca0408d","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"4a720539","execution_millis":0,"cell_id":"00008-da8a451f-3e3c-4702-a443-2e65cc56e8dd","is_code_hidden":false,"execution_start":1606702576715},"source":"def set_grap(question_num=1):\n    '''\n    集成爬虫\n\n    Paramenter:\n        question_num - 指定爬取的热点新闻数量\n    \n    Returns:\n        无\n    '''\n    # 爬取关键词\n    keyword_list = to_more_grap()\n    web_grap(keyword_list[0])\n    question_num -= 1\n\n    i = 1\n    while question_num:\n        temp_i = i\n        while len(keyword_list) <= i:\n            keyword_list += to_more_grap()\n            keyword_list = sorted(set(keyword_list),key=keyword_list.index)\n            temp_i -= 1\n            if temp_i == -1:\n                print(\"因热度关键词一致, 故抓取结束!\")\n                return\n        web_grap(keyword_list[i])\n        i += 1\n        question_num -= 1\n    print(\"抓取任务结束!\")","execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00016-fea1061e-8166-44ab-8255-b43459e056d2","output_cleared":false}},{"cell_type":"markdown","source":"**ES库的搜索函数**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00016-1084d4f3-8a48-43f9-8911-dad3b316fbfa","output_cleared":false}},{"cell_type":"markdown","source":"    1. 用于搜索题目","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00017-60c933cd-604d-40cf-a22d-004feae29c68","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00011-d12d4170-e094-4818-bd98-2c863409782f","output_cleared":false,"source_hash":"d181262e","execution_millis":0,"is_code_hidden":false,"execution_start":1606702576716},"source":"def all_es_search(key=\"title\", search=\"\"):\n    '''\n    输入某一属性, 返回所有不同值的list\n\n    Parameters:\n        key - 指搜索的关键词类型\n        search - 指搜索内容\n\n    Returns:\n        search_list - 返回相关内容的列表\n    '''\n    from elasticsearch import Elasticsearch\n    # 开始连接es库(感觉这里可以优化)\n    es = Elasticsearch(\n        ['es-cn-09k1xdlqf000a7yyn.public.elasticsearch.aliyuncs.com'],\n        http_auth=('elastic', 'Zy13720028637'),\n        port=9200,\n        use_ssl=False\n    )\n    # 开始查询(这里绝对可以优化, 先简单实现)\n    if len(search) == 0:\n        dsl = {\n            \"size\": 0,\n            \"query\":{\n                \"match_all\":{\n                    \n                }\n            },\n            \"aggs\": {\n                \"source\": {\n                    \"terms\": {\n                        \"field\": \"{}.raw\".format(key),\n                        \"size\" : 1000\n                    }\n                }\n            }\n        }\n    else:\n        dsl = {\n            \"size\": 0,\n            \"query\":{\n                \"match\":{\n                    \"title\":search\n                }\n            },\n            \"aggs\": {\n                \"source\": {\n                    \"terms\": {\n                        \"field\": \"{}.raw\".format(key)\n                    }\n                }\n            }\n        }\n\n    result = es.search(index='hot_news', doc_type='comment', body=dsl, timeout=\"30s\", ignore=400)\n\n    if \"error\" in result:\n        print(\"题目列表, 申请失败! 返回空列表\")\n        return []\n    \n    mdata = result.get(\"aggregations\").get(\"source\").get(\"buckets\")\n        \n    if not mdata:\n        return []\n    \n    search_list = []\n    for item in mdata:\n        search_list.append(item[\"key\"])\n    return search_list","execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"    2. 用于搜索指定题目, 将评论数据返回","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00019-bf84b068-96e6-4331-bd0a-b8ba21db575f","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"9c57bed7","execution_millis":0,"cell_id":"00010-4b23df9b-7dc1-4ede-a47f-ec6fb5776373","is_code_hidden":false,"execution_start":1606702576717},"source":"def es_search(search_in, stype=\"match\", source=(\"title\", )):\n    '''\n    根据search_in(指定字符串)查找相关评论, 并返回全部内容\n\n    Parameters:\n        search_in - 搜索题目\n        stype - 搜索模式\n        source - 指定es库返回的属性\n    \n    Returns:\n        mdata - 返回评论数据\n    '''\n    from elasticsearch import Elasticsearch\n    # 开始连接es库(感觉这里可以优化)\n    es = Elasticsearch(\n        ['es-cn-09k1xdlqf000a7yyn.public.elasticsearch.aliyuncs.com'],\n        http_auth=('elastic', 'Zy13720028637'),\n        port=9200,\n        use_ssl=False\n    )\n    \n    # 开始查询(这里绝对可以优化, 先简单实现)\n    dsl = {\n        \"_source\" : list(source),\n        'query': {\n            stype : {\n                'title': search_in\n            }\n        }\n    }\n\n    result = es.search(index='hot_news', doc_type='comment', body=dsl, scroll=\"30s\", size=100, timeout=\"30s\")\n    mdata = result.get(\"hits\").get(\"hits\")\n        \n    if not mdata:\n        print('empty')\n        return []\n    scroll_id = result[\"_scroll_id\"]\n    total = result[\"hits\"][\"total\"]\n    for i in range(int(total/100)):\n        res = es.scroll(scroll_id=scroll_id,scroll='30s')\n        mdata = mdata + res[\"hits\"][\"hits\"]\n    return mdata","execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"**处理从ES库获取下来的数据, 整合成列表**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00021-0f3e5b3e-3c4b-4c62-9c72-8e128cb76032","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"d65e9bdf","execution_millis":0,"cell_id":"00011-b5360511-7d8e-40ce-8ed7-7ef95c571ed5","is_code_hidden":false,"execution_start":1606702576737},"source":"def get_search_info(content, source=(\"title\",)):\n    '''\n    先简单一点, 就获取相关问题title\n    '''\n    data_list = []\n    source_list = list(source)\n    for data in content:\n        source = data[\"_source\"]\n        temp_list = []\n        for name in source_list:\n            temp_list.append(source[name])\n        \n        # 保证数据维度尽量不多\n        if len(temp_list)==1:\n            data_list.append(temp_list[0])\n        else:\n             data_list.append(temp_list)\n    return data_list","execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"**标题的打印**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00023-00c49e84-6082-4ca3-b355-c27e165b85f7","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"e04d02a7","execution_millis":1,"cell_id":"00012-0df4bed2-15fd-49b3-bf11-a122d5d48646","is_code_hidden":false,"execution_start":1606702576737},"source":"def title_print(content_info):\n    '''\n    简单实现, 就打印含有title的列表\n    '''\n    print(\"  搜索结果:\")\n    for index, title in enumerate(content_info):\n        print(\"    {}. {}\".format(index+1, title))\n    if len(content_info)==0:\n        print(\"  未搜索相关结果!\")","execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"**将评论数据存储为csv格式**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00025-3cdca606-e05c-4680-9a82-65482364ebb2","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00015-a4854c52-17c9-4f3a-9859-e0df349bce65","output_cleared":false,"source_hash":"27a87f24","execution_millis":0,"execution_start":1606702576738},"source":"def save_csv(content_info, names=(\"date\", \"describe\")):\n    '''\n    将列表数据转换为csv数据存储\n    '''\n    import pandas as pd\n    content_info = [x for x in content_info if x[1]!=\"\"]\n    dataset = pd.DataFrame(content_info, columns=names)\n    dataset.to_csv(\"news.csv\", index=None, sep=\"\\t\")","execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# **整合基于ES库搜索的相关代码**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00027-d9e57b0a-719d-4e8c-9573-81c6e98c00e3","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"1c8adddb","execution_millis":1,"cell_id":"00013-c8032651-0110-4c83-a28a-a98c7366eba6","is_code_hidden":false,"execution_start":1606702896048},"source":"def weibo_search():\n    # 输入相关查询\n    search_in = input()\n    # 从es库查询结果\n    print(\"  \" + search_in)\n    content = all_es_search(search=search_in)\n    # 打印内容\n    title_print(content)\n\n    if len(content)==0:\n        return\n\n    # 二级执行菜单\n    print(\"\\n------二级执行菜单------\")\n    print(\"1. 选择指定题目--返回评论数据\")\n    print(\"2. 返回一级菜单\")\n    select_num = int(input())\n    if select_num==1:\n        print(\"\\n  请选择题目的标题号:\")\n        title_num = int(input())\n        print(\"    你选择的标题号: {}\".format(title_num))\n        content = es_search(content[title_num-1], stype=\"match_phrase\", source=(\"createData\", \"describe\",))\n        content_info = get_search_info(content, source=(\"createData\", \"describe\",))\n        # print(\"数据数量:{}\".format(len(content_info)))\n        # print(\"数据元素:{}\".format(content_info[0]))\n        # save_csv(content_info)\n    else:\n        return 0","execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00030-bce3c4a8-a7c3-46d1-9b6d-08bbfce226ae","output_cleared":false}},{"cell_type":"markdown","source":"# **结果可视化**","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00016-86affb8b-9fa0-4dc7-972f-4e9b5e113308","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00016-5dfff700-c791-4c2d-8e5b-6d0f401c2383","output_cleared":false,"source_hash":"9fbf606f","execution_millis":0,"execution_start":1606702576764},"source":"class eval_visual():\n    '''\n    用于可视化评论分布, 暂定目标饼图和线性图\n    '''\n    def __init__(self, title, comment):\n        self.title = title\n        self.comment = comment  # [(date, price), ...]\n        self.data_dict = {}\n        self.deal_data()\n    \n    def deal_data(self):\n        # 处理数据\n        if type(self.comment) != list:\n            print(\"数据类型为:{}\\t处理失败!\".format(type(self.comment)))\n            return\n        # 需要整体的正类的数据个数, 负类的数据个数\n        if type(self.comment[0][1]) != int:\n            self.comment = [[x[0], int(x[1])] for x in self.comment]\n        total = len(self.comment)\n        total_0_data = [x for x in self.comment if x[1]==0]\n        self.data_dict[\"total_data\"] = {}\n        self.data_dict[\"total_data\"][\"0\"] = len(total_0_data)\n        total_1_data = [x for x in self.comment if x[1]==1]\n        self.data_dict[\"total_data\"][\"1\"] = len(total_1_data)\n        \n        # 需要不同时间下, 正类的数据个数, 负类的数据个数\n        self.data_dict[\"date_data\"] = {}\n        self.date = list(set([x[0] for x in self.comment]))\n        self.date.sort()\n        ## 假设正类和负类的每天都会有\n        self.data_dict[\"date_data\"][\"0\"] = []\n        self.data_dict[\"date_data\"][\"1\"] = []\n        for x in self.date:\n            self.data_dict[\"date_data\"][\"0\"].append(len([y for y in total_0_data if y[0]==x]))\n            self.data_dict[\"date_data\"][\"1\"].append(len([y for y in total_1_data if y[0]==x]))\n\n\n    def paint(self):\n        import matplotlib.pyplot as plt\n        plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n        plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n        # 划分子图\n        fig, ax = plt.subplots(1,2, figsize=(18, 6))\n        fig.suptitle(self.title, fontsize=25)\n        # 画饼图\n        ax[0].set_title(\"情感分析\", fontsize=16)\n        self.paint_pie(ax[0])\n        # 画线性图\n        ax[1].set_title(\"时间趋势\", fontsize=16)\n        self.paint_line(ax[1])\n        # 展示\n        plt.show()\n    \n    def paint_pie(self, ax):\n        total_0_num = self.data_dict[\"total_data\"][\"0\"]\n        total_1_num = self.data_dict[\"total_data\"][\"1\"]\n        sizes = [total_0_num, total_1_num]\n        labels = [\"Bad\", \"Good\"]\n        # 画图\n        ax.pie(sizes, labels=labels, autopct='%.2f%%', shadow=True, startangle=90)\n    \n    def paint_line(self, ax):\n        index = list(range(len(self.date)))\n        data_0 = self.data_dict[\"date_data\"][\"0\"]\n        data_1 = self.data_dict[\"date_data\"][\"1\"]\n        ax.plot(index, data_0, label=\"bad\")\n        ax.plot(index, data_1, label=\"good\")\n        ax.set_xticks(index)\n        ax.set_xticklabels(self.date, rotation=45)\n        ax.set_xlabel(\"日期\", fontsize=12)\n        ax.set_ylabel(\"数量\", fontsize=12)\n        ax.legend()","execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"output_cleared":false,"source_hash":"e4740f0c","execution_millis":1,"cell_id":"00014-de4f7c5f-de9b-4c22-acd0-235f9e3b8dd5","execution_start":1606704382796},"source":"def main():\n    while True:\n        print(\"\\n------一级执行菜单------\")\n        print(\"1. 简单抓取\")\n        print(\"2. 相关搜索\")\n        print(\"3. 退出程序\")\n        select_num = int(input())\n        if select_num==1:\n            set_grap(10)\n        elif select_num==2:\n            print(\"\\n  请输入内容:\")\n            weibo_search()\n        else:\n            print(\"\\n成功退出!\")\n            break","execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00021-83ad12c6-1bc9-465c-9bfd-c83f7975736f","output_cleared":false,"source_hash":"286a4539","execution_millis":1037512,"execution_start":1606704383781},"source":"main()","execution_count":62,"outputs":[{"name":"stdout","text":"\n------一级执行菜单------\n1. 简单抓取\n2. 相关搜索\n3. 退出程序\n\n抓取热度:上海地铁禁止电子设备声音外放\n 已抓取20条评论!!\n 已抓取40条评论!!\n 已抓取60条评论!!\n 已抓取78条评论!!\n 已抓取97条评论!!\n 已抓取116条评论!!\n 已抓取134条评论!!\n 已抓取151条评论!!\n 已抓取171条评论!!\n 已抓取189条评论!!\n 已抓取207条评论!!\n 已抓取226条评论!!\n 已抓取244条评论!!\n 已抓取263条评论!!\n 已抓取283条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取303条评论!!\n 已抓取323条评论!!\n 已抓取343条评论!!\n 已抓取355条评论!!\n 已抓取356条评论!!\n 已抓取376条评论!!\n 已抓取396条评论!!\n 已抓取416条评论!!\n 已抓取436条评论!!\n 已抓取453条评论!!\n 已抓取472条评论!!\n 已抓取480条评论!!\n上海地铁禁止电子设备声音外放抓取结束!\n\n抓取热度:秋冬底妆避雷\n 已抓取20条评论!!\n 已抓取38条评论!!\n 已抓取50条评论!!\n 已抓取54条评论!!\n 已抓取74条评论!!\n 已抓取93条评论!!\n 已抓取112条评论!!\n 已抓取115条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取135条评论!!\n 已抓取153条评论!!\n 已抓取173条评论!!\n 已抓取193条评论!!\n 已抓取213条评论!!\n 已抓取233条评论!!\n 已抓取252条评论!!\n 已抓取256条评论!!\n 已抓取257条评论!!\n 已抓取258条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n秋冬底妆避雷抓取结束!\n\n抓取热度:汪峰大女儿侧颜\n 已抓取20条评论!!\n 已抓取39条评论!!\n 已抓取59条评论!!\n 已抓取78条评论!!\n 已抓取98条评论!!\n 已抓取118条评论!!\n 已抓取138条评论!!\n 已抓取157条评论!!\n 已抓取176条评论!!\n 已抓取196条评论!!\n 已抓取216条评论!!\n 已抓取236条评论!!\n 已抓取256条评论!!\n 已抓取276条评论!!\n 已抓取296条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取316条评论!!\n 已抓取336条评论!!\n 已抓取356条评论!!\n 已抓取376条评论!!\n 已抓取396条评论!!\n 已抓取416条评论!!\n 已抓取436条评论!!\n 已抓取456条评论!!\n 已抓取476条评论!!\n 已抓取496条评论!!\n 已抓取513条评论!!\n 已抓取521条评论!!\n 已抓取523条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n汪峰大女儿侧颜抓取结束!\n\n抓取热度:校方回应女生将卖淫经历发网上\n 已抓取20条评论!!\n 已抓取40条评论!!\n 已抓取60条评论!!\n 已抓取80条评论!!\n 已抓取100条评论!!\n 已抓取120条评论!!\n 已抓取140条评论!!\n 已抓取160条评论!!\n 已抓取178条评论!!\n 已抓取197条评论!!\n 已抓取217条评论!!\n 已抓取237条评论!!\n 已抓取256条评论!!\n 已抓取276条评论!!\n 已抓取296条评论!!\nip被封!, 等候3s\n  跳出此次申请...\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取300条评论!!\n校方回应女生将卖淫经历发网上抓取结束!\n\n抓取热度:王一博卖货风格\n 已抓取20条评论!!\n 已抓取40条评论!!\n 已抓取60条评论!!\n 已抓取79条评论!!\n 已抓取98条评论!!\n 已抓取118条评论!!\n 已抓取137条评论!!\n 已抓取157条评论!!\n 已抓取176条评论!!\n 已抓取195条评论!!\n 已抓取213条评论!!\n 已抓取233条评论!!\n 已抓取253条评论!!\n 已抓取272条评论!!\n 已抓取290条评论!!\n 已抓取310条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取330条评论!!\n 已抓取350条评论!!\n 已抓取370条评论!!\n 已抓取389条评论!!\n 已抓取409条评论!!\n 已抓取428条评论!!\n 已抓取448条评论!!\n 已抓取467条评论!!\n 已抓取485条评论!!\n 已抓取501条评论!!\n 已抓取516条评论!!\n 已抓取531条评论!!\n 已抓取548条评论!!\n 已抓取561条评论!!\n 已抓取578条评论!!\n 已抓取592条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取598条评论!!\n 已抓取605条评论!!\n王一博卖货风格抓取结束!\n\n抓取热度:九层妖塔原型古墓\n 已抓取20条评论!!\n 已抓取40条评论!!\n 已抓取59条评论!!\n 已抓取79条评论!!\n 已抓取98条评论!!\n 已抓取117条评论!!\n 已抓取137条评论!!\n 已抓取155条评论!!\n 已抓取174条评论!!\n 已抓取192条评论!!\n 已抓取210条评论!!\n 已抓取224条评论!!\n 已抓取243条评论!!\n 已抓取263条评论!!\n 已抓取283条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取293条评论!!\n 已抓取313条评论!!\n 已抓取332条评论!!\n 已抓取335条评论!!\n九层妖塔原型古墓抓取结束!\n\n抓取热度:伊朗核物理学家遭暗杀细节\n 已抓取20条评论!!\n 已抓取40条评论!!\n 已抓取59条评论!!\n 已抓取78条评论!!\n 已抓取93条评论!!\n 已抓取110条评论!!\n 已抓取128条评论!!\n 已抓取147条评论!!\n 已抓取165条评论!!\n 已抓取182条评论!!\n/opt/venv/lib/python3.7/site-packages/bs4/__init__.py:336: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n  MarkupResemblesLocatorWarning\n 已抓取201条评论!!\n 已抓取220条评论!!\n 已抓取239条评论!!\n 已抓取257条评论!!\n 已抓取277条评论!!\n 已抓取287条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取307条评论!!\n 已抓取327条评论!!\n 已抓取335条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n伊朗核物理学家遭暗杀细节抓取结束!\n\n抓取热度:TheShy 最受欢迎选手\n 已抓取20条评论!!\n 已抓取40条评论!!\n 已抓取60条评论!!\n 已抓取80条评论!!\n 已抓取100条评论!!\n 已抓取118条评论!!\n 已抓取138条评论!!\n 已抓取158条评论!!\n 已抓取177条评论!!\n 已抓取197条评论!!\n 已抓取217条评论!!\n 已抓取235条评论!!\n 已抓取255条评论!!\n 已抓取275条评论!!\n 已抓取295条评论!!\n 已抓取312条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取332条评论!!\n 已抓取352条评论!!\n 已抓取372条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取374条评论!!\nTheShy 最受欢迎选手抓取结束!\n\n抓取热度:11月的最后一天\n 已抓取20条评论!!\n 已抓取40条评论!!\n 已抓取60条评论!!\n 已抓取79条评论!!\n 已抓取97条评论!!\n 已抓取115条评论!!\n 已抓取134条评论!!\n 已抓取152条评论!!\n 已抓取170条评论!!\n 已抓取188条评论!!\n 已抓取207条评论!!\n 已抓取226条评论!!\n 已抓取243条评论!!\n 已抓取262条评论!!\n 已抓取279条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取299条评论!!\n 已抓取319条评论!!\n 已抓取339条评论!!\n 已抓取359条评论!!\n 已抓取379条评论!!\n 已抓取399条评论!!\n 已抓取418条评论!!\n 已抓取437条评论!!\n 已抓取455条评论!!\n 已抓取474条评论!!\n 已抓取492条评论!!\n 已抓取512条评论!!\n 已抓取531条评论!!\n 已抓取550条评论!!\n 已抓取569条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取589条评论!!\n 已抓取608条评论!!\n 已抓取625条评论!!\n 已抓取643条评论!!\n 已抓取659条评论!!\n 已抓取677条评论!!\n 已抓取696条评论!!\n 已抓取702条评论!!\n 已抓取708条评论!!\n 已抓取710条评论!!\n11月的最后一天抓取结束!\n\n抓取热度:P2P正式退出历史舞台\n 已抓取20条评论!!\n 已抓取39条评论!!\n 已抓取59条评论!!\n 已抓取77条评论!!\n 已抓取97条评论!!\n 已抓取117条评论!!\n 已抓取135条评论!!\n 已抓取155条评论!!\n 已抓取175条评论!!\n 已抓取195条评论!!\n 已抓取213条评论!!\n 已抓取232条评论!!\n 已抓取252条评论!!\n 已抓取272条评论!!\n 已抓取292条评论!!\n 已抓取305条评论!!\nip被封!, 等候3s\n  跳出此次申请...\n 已抓取325条评论!!\n 已抓取345条评论!!\n 已抓取359条评论!!\n 已抓取362条评论!!\n 已抓取381条评论!!\n 已抓取399条评论!!\n 已抓取407条评论!!\nP2P正式退出历史舞台抓取结束!\n抓取任务结束!\n\n------一级执行菜单------\n1. 简单抓取\n2. 相关搜索\n3. 退出程序\n\n成功退出!\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00036-e6bca4ad-7484-4081-8b28-cd5b742c4c81","output_cleared":false,"source_hash":"b623e53d","execution_start":1606702682289,"execution_millis":0},"source":"","execution_count":48,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"b536b628-e346-45c8-937a-c15451457e3b","deepnote_execution_queue":[]}}